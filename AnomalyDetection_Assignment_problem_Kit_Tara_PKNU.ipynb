{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "09673793-0704-46c4-bf9c-03abe274a483",
      "metadata": {
        "id": "09673793-0704-46c4-bf9c-03abe274a483"
      },
      "source": [
        "## Special Topics to Machine Learning Project Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bddbdfb-eba7-449b-85a3-15f8cda0f13d",
      "metadata": {
        "id": "0bddbdfb-eba7-449b-85a3-15f8cda0f13d"
      },
      "source": [
        "* After you run the above code, data will be saved in the df variable.\n",
        "* The dataset is collected from sensors attached to the vessel main engine (to keep the confidential issue, every column name and its sensor value is normalized).\n",
        "* The objective is to train an anomaly detector using Isolation Forest.\n",
        "* There is a label in the dataset (column class), where 0 means a normal datapoint and 1 means an anomalous datapoint.\n",
        "* You will need to preprocess the data, split it into training and testing sets, and then apply the Isolation Forest algorithm to detect anomalies.\n",
        "* Finally, evaluate the performance of your model using appropriate metrics and visualize the results to understand the model's effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "89-8CHOTcFvx"
      },
      "id": "89-8CHOTcFvx"
    },
    {
      "cell_type": "markdown",
      "id": "4e3a9665-ba0d-4ecb-a407-f7c021a7737b",
      "metadata": {
        "id": "4e3a9665-ba0d-4ecb-a407-f7c021a7737b"
      },
      "source": [
        "## 1. Importing dataset and module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2ea336d6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-05T07:01:54.440019Z",
          "start_time": "2024-06-05T07:01:51.507887Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ea336d6",
        "outputId": "45da1033-971d-44cd-b653-9ff6d748320b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyod\n",
            "  Downloading pyod-2.0.0.tar.gz (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from pyod) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyod) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from pyod) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from pyod) (1.2.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->pyod) (0.41.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->pyod) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pyod) (1.16.0)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-2.0.0-py3-none-any.whl size=196324 sha256=9c6d7baf59d1d3ffd3e36999bcfcc8aa4fd2e1329f196b0a798fd56f41d5a895\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/0e/91/96b270e6741d4eece88727489411330226ff47ac1cb9ea0097\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-2.0.0\n"
          ]
        }
      ],
      "source": [
        "# To do the assignment you have to run this cell\n",
        "# After run this code, your colab will install anomaly detection module (but their interface is the same with sklearn)\n",
        "!pip install pyod"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MUmp66kpngp1"
      },
      "id": "MUmp66kpngp1"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8b31876e-c0bc-493e-b75b-55ba1a0a52f0",
      "metadata": {
        "id": "8b31876e-c0bc-493e-b75b-55ba1a0a52f0"
      },
      "outputs": [],
      "source": [
        "# Step 0: Import necessary modeuls\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyod.models.iforest import IForest\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Step 1: Load the dataset from pyod\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ralbu85/STML/main/assignment_data.csv.csv')\n",
        "df = df[['Dim_0','Dim_16','Dim_17','Dim_18','Dim_19','Dim_20','class']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef426c7-166f-4d34-937a-0be4b6a428bf",
      "metadata": {
        "id": "aef426c7-166f-4d34-937a-0be4b6a428bf"
      },
      "outputs": [],
      "source": [
        "# The shape of the dataset will be like that\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cf5dec9-34e0-4afc-9e1c-b9d05440001c",
      "metadata": {
        "id": "0cf5dec9-34e0-4afc-9e1c-b9d05440001c"
      },
      "source": [
        "## Problem 1\n",
        "* Complete the following cell to calculate the number of normal and abnormal data points.\n",
        "* Save the number of normal data points in the variable 'n_normal' and the number of abnormal data points in the variable 'n_anormal'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a8fd22b2-4737-4595-85ab-cf5b87bab145",
      "metadata": {
        "id": "a8fd22b2-4737-4595-85ab-cf5b87bab145"
      },
      "outputs": [],
      "source": [
        "## Complete following code int the cell\n",
        "n_normal = df[df['class'] == 0].shape[0]\n",
        "n_anormal = df[df['class'] == 1].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "acd05506-6643-4d5e-926e-0ec2901a8a87",
      "metadata": {
        "id": "acd05506-6643-4d5e-926e-0ec2901a8a87",
        "outputId": "28c6fac4-4206-40c0-d9ec-d03bbcf72591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of normal data points: 6666\n",
            "Number of abnormal data points: 534\n"
          ]
        }
      ],
      "source": [
        "## Answer checking (If your are correct and run the following cell, the following will be printed.\n",
        "print(f\"Number of normal data points: {n_normal}\")\n",
        "print(f\"Number of abnormal data points: {n_anormal}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d080e76-d92b-4eda-8f35-c87dfd677de1",
      "metadata": {
        "id": "0d080e76-d92b-4eda-8f35-c87dfd677de1"
      },
      "source": [
        "## Problem 2\n",
        "* Next we will split the dataset into training/validation/testing\n",
        "* First, 75% of normal data will be used for trining\n",
        "* Second, remaining 25% normal data and entire anormal data will be evenly splitted into validation and testing dataset\n",
        "* Complete the following cell to split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "08159c8f-780e-40c4-846a-04f50ce80b3b",
      "metadata": {
        "tags": [],
        "id": "08159c8f-780e-40c4-846a-04f50ce80b3b"
      },
      "outputs": [],
      "source": [
        "## You don't need to code, but you have to run\n",
        "\n",
        "## Split the data with respect to the normal/anormal\n",
        "df_normal = df[df['class']==0]\n",
        "df_anormal = df[df['class']==1]\n",
        "\n",
        "## Splitting data for normal\n",
        "y_normal = df_normal['class']\n",
        "X_normal = df_normal.drop(columns=['class'])\n",
        "\n",
        "## Splitting data for anormal\n",
        "y_anormal = df_anormal['class']\n",
        "X_anormal = df_anormal.drop(columns=['class'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "44a18470-3185-42fb-8c50-a50195382595",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-05T07:14:12.070887Z",
          "start_time": "2024-06-05T07:14:12.042988Z"
        },
        "id": "44a18470-3185-42fb-8c50-a50195382595"
      },
      "outputs": [],
      "source": [
        "## Complete following code int the cell\n",
        "\n",
        "# Split normal data into training (75%) and the remaining (25%)\n",
        "X_normal_train, X_normal_temp, y_normal_train, y_normal_temp = train_test_split(X_normal, y_normal , test_size=0.25, random_state=42) # Complete the code\n",
        "X_normal_val, X_normal_test, y_normal_val, y_normal_test = train_test_split(X_normal_temp , y_normal_temp, test_size=0.5, random_state=42) # Complete the code\n",
        "\n",
        "# Use all the anormal data for validation and testing\n",
        "X_anormal_val, X_anormal_test, y_anormal_val, y_anormal_test = train_test_split(X_anormal, y_anormal , test_size=0.5, random_state=42) # Complete the code\n",
        "\n",
        "# Combine normal and anormal data for validation and testing\n",
        "X_val = np.vstack((X_normal_val, X_anormal_val))\n",
        "y_val = np.hstack((y_normal_val, y_anormal_val))\n",
        "\n",
        "X_test = np.vstack((X_normal_test, X_anormal_test))\n",
        "y_test = np.hstack((y_normal_test, y_anormal_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a17bb131-4568-4ea6-9e9a-238e2dec070e",
      "metadata": {
        "id": "a17bb131-4568-4ea6-9e9a-238e2dec070e",
        "outputId": "a3af642a-341e-4ae4-bb22-3a2adecfab1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (4999, 6)\n",
            "Shape of X_val: (1100, 6)\n",
            "Shape of X_test: (1101, 6)\n"
          ]
        }
      ],
      "source": [
        "## Answer checking (If your are correct and run the following cell, the following will be printed.\n",
        "print(f\"Shape of X_train: {X_normal_train.shape}\")\n",
        "print(f\"Shape of X_val: {X_val.shape}\")\n",
        "print(f\"Shape of X_test: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35f368ba-0a84-427d-bfa9-6873569a1910",
      "metadata": {
        "id": "35f368ba-0a84-427d-bfa9-6873569a1910"
      },
      "source": [
        "## Problem 3.\n",
        "* Next we will perform hyper parameter tuning of Isolation Forest to find the best model using Validation Dataset\n",
        "* Note that IForest model use same API for sklearn\n",
        "* However, we cannot directly run GridSearchCV in this setting\n",
        "* So we will directly iterate the entire hyper parameter spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cebacb67-92a1-4cd1-b1ce-b8207713c3ab",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-05T07:15:52.258548Z",
          "start_time": "2024-06-05T07:15:06.769226Z"
        },
        "tags": [],
        "id": "cebacb67-92a1-4cd1-b1ce-b8207713c3ab",
        "outputId": "f778f85a-cc54-43d1-8fd5-bef3d7b800af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_estimators': 100, 'max_samples': 'auto', 'contamination': 0.5, 'max_features': 0.8}\n",
            "Best Validation F1-Score: 0.5263157894736842\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_samples': ['auto'],\n",
        "    'contamination': [0.1, 0.2,0.3,0.5],\n",
        "    'max_features': [1.0, 0.5, 0.8]\n",
        "}\n",
        "\n",
        "# Function to train and evaluate IsolationForest with given hyperparameters\n",
        "# We will use f1 metric for finding best hyper parameter\n",
        "def train_and_evaluate(params):\n",
        "    iso_forest = IForest(\n",
        "        n_estimators=params['n_estimators'],\n",
        "        max_samples=params['max_samples'],\n",
        "        contamination=params['contamination'],\n",
        "        max_features=params['max_features'],\n",
        "        random_state=42\n",
        "    )\n",
        "    iso_forest.fit(X_val)\n",
        "    y_val_pred = iso_forest.predict(X_val)\n",
        "    # Convert predictions to binary labels\n",
        "    y_val_pred = [1 if x == 1 else 0 for x in y_val_pred]\n",
        "\n",
        "    metric = f1_score(y_val, y_val_pred)\n",
        "    return metric\n",
        "\n",
        "# Perform manual hyperparameter tuning\n",
        "best_params = None\n",
        "best_metric = -np.inf\n",
        "\n",
        "for n_estimators in param_grid['n_estimators']:\n",
        "    for max_samples in param_grid['max_samples']:\n",
        "        for contamination in param_grid['contamination']:\n",
        "            for max_features in param_grid['max_features']:\n",
        "                params = {\n",
        "                    'n_estimators': n_estimators,\n",
        "                    'max_samples': max_samples,\n",
        "                    'contamination': contamination,\n",
        "                    'max_features': max_features\n",
        "                }\n",
        "                metric = train_and_evaluate(params)\n",
        "                if metric > best_metric:\n",
        "                    best_metric = metric\n",
        "                    best_params = params\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Best Validation F1-Score: {best_metric}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74523ea6-00fd-4974-b932-ca3301efd988",
      "metadata": {
        "id": "74523ea6-00fd-4974-b932-ca3301efd988"
      },
      "source": [
        "## Problem 4.\n",
        "* Now the best params is stored in 'best_params'\n",
        "* You will now re-run the IsolationForest model with best hyper parameters using TEST dataset\n",
        "* Also, we will now check the performance of our best model using various metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "237cc793-502f-48af-9d9a-994a75c03ab9",
      "metadata": {
        "id": "237cc793-502f-48af-9d9a-994a75c03ab9",
        "outputId": "081adb96-4840-470a-da95-cd9cf98ba104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Precision: 0.38088445078459343\n",
            "Test Recall: 1.0\n",
            "Test F1-Score: 0.5516528925619835\n",
            "Test AUC-ROC: 0.7398081534772183\n"
          ]
        }
      ],
      "source": [
        "# Train the best model on the training data\n",
        "best_iso_forest = IForest(\n",
        "    n_estimators=best_params['n_estimators'],\n",
        "    max_samples=best_params['max_samples'],\n",
        "    contamination=best_params['contamination'],\n",
        "    max_features=best_params['max_features'],\n",
        "    random_state=42\n",
        ")\n",
        "best_iso_forest.fit(X_normal_train)\n",
        "\n",
        "# Predicting anomalies on testing set\n",
        "y_test_pred = best_iso_forest.predict(X_test)\n",
        "\n",
        "# Evaluating on testing set\n",
        "precision_test = precision_score(y_test, y_test_pred)\n",
        "recall_test = recall_score(y_test, y_test_pred)\n",
        "f1_test = f1_score(y_test, y_test_pred)\n",
        "roc_auc_test = roc_auc_score(y_test, y_test_pred)\n",
        "\n",
        "print(f'Test Precision: {precision_test}')\n",
        "print(f'Test Recall: {recall_test}')\n",
        "print(f'Test F1-Score: {f1_test}')\n",
        "print(f'Test AUC-ROC: {roc_auc_test}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f41c93a2-9d5d-40c3-8670-342500c652c1",
      "metadata": {
        "id": "f41c93a2-9d5d-40c3-8670-342500c652c1"
      },
      "source": [
        "## Problem 5.\n",
        "* Also we want to examine confusion matrix of our result\n",
        "* Try to extract True Positive, False Positive, True Negative, False Negative\n",
        "* You have to search confusion_matrix API of scikit learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c4a1bec8-6d1c-4c69-874c-4a58b6afa86b",
      "metadata": {
        "id": "c4a1bec8-6d1c-4c69-874c-4a58b6afa86b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "tp = cm[1, 1]\n",
        "fp = cm[0, 1]\n",
        "tn = cm[0, 0]\n",
        "fn = cm[1, 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "43b36fe9-f7b0-451c-9f03-4438a8957199",
      "metadata": {
        "id": "43b36fe9-f7b0-451c-9f03-4438a8957199",
        "outputId": "08046785-db82-4c1f-ab75-13c98160ba47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Positive: 267\n",
            "False Positive: 434\n",
            "True Negative: 400\n",
            "False Negative: 0\n"
          ]
        }
      ],
      "source": [
        "## Answer checking (If your are correct and run the following cell, the following will be printed.\n",
        "print(f\"True Positive: {tp}\")\n",
        "print(f\"False Positive: {fp}\")\n",
        "print(f\"True Negative: {tn}\")\n",
        "print(f\"False Negative: {fn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "477141db-1c53-41ed-9075-97ebafb9010a",
      "metadata": {
        "id": "477141db-1c53-41ed-9075-97ebafb9010a"
      },
      "source": [
        "## Problem 6 (Extra Credit)\n",
        "I am using the CBLOF (Cluster-Based Local Outlier Factor) algorithm from the PYOD library for anomaly detection\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyod.models.cblof import CBLOF"
      ],
      "metadata": {
        "id": "Ehfts5XcxhTd"
      },
      "id": "Ehfts5XcxhTd",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "cbe1f0d4-88e3-4a08-a873-0b0a7626e4c7",
      "metadata": {
        "id": "cbe1f0d4-88e3-4a08-a873-0b0a7626e4c7"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter grid for CBLOF\n",
        "param_grid_cblof = {\n",
        "    'n_clusters': [5, 10, 15],\n",
        "    'contamination': [0.1, 0.2, 0.3, 0.5]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train and evaluate CBLOF\n",
        "def train_and_evaluate_cblof(params):\n",
        "    cblof = CBLOF(\n",
        "        n_clusters=params['n_clusters'],\n",
        "        contamination=params['contamination']\n",
        "    )\n",
        "    cblof.fit(X_val)\n",
        "    y_val_pred = cblof.predict(X_val)\n",
        "    y_val_pred = [1 if x == 1 else 0 for x in y_val_pred]\n",
        "    metric = f1_score(y_val, y_val_pred)\n",
        "    return metric"
      ],
      "metadata": {
        "id": "b3b5G3JUxap0"
      },
      "id": "b3b5G3JUxap0",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform manual hyperparameter tuning for CBLOF\n",
        "best_params_cblof = None\n",
        "best_metric_cblof = -np.inf\n",
        "\n",
        "for n_clusters in param_grid_cblof['n_clusters']:\n",
        "    for contamination in param_grid_cblof['contamination']:\n",
        "        params = {\n",
        "            'n_clusters': n_clusters,\n",
        "            'contamination': contamination\n",
        "        }\n",
        "        metric = train_and_evaluate_cblof(params)\n",
        "        if metric > best_metric_cblof:\n",
        "            best_metric_cblof = metric\n",
        "            best_params_cblof = params\n",
        "\n",
        "print(f'Best Hyperparameters for CBLOF: {best_params_cblof}')\n",
        "print(f'Best Validation F1-Score for CBLOF: {best_metric_cblof}')"
      ],
      "metadata": {
        "id": "0uAwTTPGxcG0",
        "outputId": "9481a829-b81f-4c65-a35b-2a5930880c29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0uAwTTPGxcG0",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters for CBLOF: {'n_clusters': 10, 'contamination': 0.3}\n",
            "Best Validation F1-Score for CBLOF: 0.4489112227805695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the best CBLOF model on the test data\n",
        "best_cblof = CBLOF(\n",
        "    n_clusters=best_params_cblof['n_clusters'],\n",
        "    contamination=best_params_cblof['contamination']\n",
        ")\n",
        "best_cblof.fit(X_normal_train)\n",
        "\n",
        "y_test_pred_cblof = best_cblof.predict(X_test)\n",
        "y_test_pred_cblof = [1 if x == 1 else 0 for x in y_test_pred_cblof]\n",
        "\n",
        "precision_test_cblof = precision_score(y_test, y_test_pred_cblof)\n",
        "recall_test_cblof = recall_score(y_test, y_test_pred_cblof)\n",
        "f1_test_cblof = f1_score(y_test, y_test_pred_cblof)\n",
        "roc_auc_test_cblof = roc_auc_score(y_test, y_test_pred_cblof)\n",
        "\n",
        "print(f'CBLOF Test Precision: {precision_test_cblof}')\n",
        "print(f'CBLOF Test Recall: {recall_test_cblof}')\n",
        "print(f'CBLOF Test F1-Score: {f1_test_cblof}')\n",
        "print(f'CBLOF Test AUC-ROC: {roc_auc_test_cblof}')"
      ],
      "metadata": {
        "id": "GvUUQH6jxdp2",
        "outputId": "68cddc96-aeff-46a1-d680-10eac697e0b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GvUUQH6jxdp2",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CBLOF Test Precision: 0.34615384615384615\n",
            "CBLOF Test Recall: 0.5393258426966292\n",
            "CBLOF Test F1-Score: 0.4216691068814056\n",
            "CBLOF Test AUC-ROC: 0.6065933769838062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix for CBLOF\n",
        "cm_cblof = confusion_matrix(y_test, y_test_pred_cblof)\n",
        "tp_cblof = cm_cblof[1, 1]\n",
        "fp_cblof = cm_cblof[0, 1]\n",
        "tn_cblof = cm_cblof[0, 0]\n",
        "fn_cblof = cm_cblof[1, 0]\n",
        "\n",
        "print(f'CBLOF True Positives (TP): {tp_cblof}')\n",
        "print(f'CBLOF False Positives (FP): {fp_cblof}')\n",
        "print(f'CBLOF True Negatives (TN): {tn_cblof}')\n",
        "print(f'CBLOF False Negatives (FN): {fn_cblof}')"
      ],
      "metadata": {
        "id": "_z14F4FZxoyt",
        "outputId": "ab796548-870e-47d3-c1d1-3ed2f6a79803",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_z14F4FZxoyt",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CBLOF True Positives (TP): 144\n",
            "CBLOF False Positives (FP): 272\n",
            "CBLOF True Negatives (TN): 562\n",
            "CBLOF False Negatives (FN): 123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QQopfrXZxrRn"
      },
      "id": "QQopfrXZxrRn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}